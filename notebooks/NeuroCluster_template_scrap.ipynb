{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroCluster:\n",
    "<font size= 4> A Python toolbox for nonparametric cluster-based statistical testing of neurophysiological data with respect to continuous predictors \n",
    "\n",
    "First Authors: Alexandra Fink-Skular & Christina Maher  \\\n",
    "Updated: 11/10/2024 by AFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeuroCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running NeuroCluster from a local repo (not through a virtual environment package install)\n",
    "user_base_dir   = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/neuro_cluster_proj/'\n",
    "# user_base_dir   = '/Path/To/NeuroCluster/NeuroCluster/'\n",
    "sample_data_dir = f'{user_base_dir}NeuroCluster/data/'\n",
    "results_dir     = f'{user_base_dir}NeuroCluster/results/'\n",
    "\n",
    "# Let's store the date so we can keep track of versions\n",
    "date = datetime.date.today().strftime('%m%d%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom functions\n",
    "import sys\n",
    "sys.path.append(f'{user_base_dir}NeuroCluster/')\n",
    "import NeuroCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurocluster Workflow\n",
    "\n",
    "This notebook performs a nonparametric permutation-based cluster test on continuous behavioral predictors for one example electrode. The workflow is outlined schematically below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/opt/anaconda3/envs/neurocluster_env/lib/python3.10/site-packages/NeuroCluster/workflow/Figure1_workflow.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(package_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigure1_workflow.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m display(\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m750\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurocluster_env/lib/python3.10/site-packages/IPython/core/display.py:1053\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurocluster_env/lib/python3.10/site-packages/IPython/core/display.py:371\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurocluster_env/lib/python3.10/site-packages/IPython/core/display.py:1088\u001b[0m, in \u001b[0;36mImage.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurocluster_env/lib/python3.10/site-packages/IPython/core/display.py:397\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/opt/anaconda3/envs/neurocluster_env/lib/python3.10/site-packages/NeuroCluster/workflow/Figure1_workflow.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import os \n",
    "\n",
    "# Get the base path of the installed NeuroCluster package\n",
    "package_dir = os.path.dirname(NeuroCluster.__file__)\n",
    "\n",
    "# Construct the path to the image\n",
    "image_path = os.path.join(package_dir, \"workflow\", \"Figure1_workflow.png\")\n",
    "\n",
    "# Display the image\n",
    "display(Image(filename=image_path, width=750))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Format input data (neural and behavioral)\n",
    "\n",
    "The sample data for this notebook includes: \n",
    "- neural data: np.array (n_channels x n_trials x n_freqs x n_times)\n",
    "- behavior data: pd.DataFrame (n_trials x n_variables)\n",
    "\n",
    "These variables are extracted from an `mne.time_frequency.EpochsTFR` which is a spatiotemporal representation of neural data that includes power across trials, frequencies, and timepoints. Note, for this notebook we provide the neural and behavioral data in `np.array` *a priori*. These data can be found in the `sample_data_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some example code, loading an `EpochsTFR` following preprocessing with  [MNE-Python](https://mne.tools/stable/index.html) and creating a neural data file (i.e., `channel_13.npy`) and our behavioral regressors (i.e., `sample_behavior.csv`):\n",
    "\n",
    "`# load EpochsTFR data`\n",
    "\n",
    "\n",
    "`power_epochs = mne.time_frequency.read_tfrs(fname=f'{tfr_dir}{subj_id}_tfr.h5')[0]`\n",
    "\n",
    "\n",
    "\n",
    "`# save data from each channel to a .npy file`\n",
    "\n",
    "\n",
    "`for i in range(len(power_epochs.info['ch_names'])):`\n",
    "\n",
    "        channel = power_epochs.info['ch_names'][i]\n",
    "\n",
    "        data = power_epochs.data[i]\n",
    "\n",
    "        np.save(f'{results_dir}{channel}.npy', data)\n",
    "\n",
    "\n",
    "\n",
    "`# save metadata as a numpy array to a .csv file`\n",
    "\n",
    "\n",
    "`metadata = pd.DataFrame(power_epochs.metadata)`\n",
    "\n",
    "\n",
    "`metadata.to_csv(f'{results_dir}sample_behavior.csv', index=False)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, let's load our template neural data into a dictionary and load the DataFrame of our behavioral predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ieeg_files = glob(f'{sample_data_dir}*.npy')\n",
    "sample_ieeg_dict  = {f'{file.split(\"/\")[-1].split(\".\")[0]}':np.load(file) for file in sample_ieeg_files}\n",
    "ieeg_channels     = list(sample_ieeg_dict.keys())\n",
    "sample_behav      = pd.read_csv(f'{sample_data_dir}sample_behavior.csv')\n",
    "freqs             = np.logspace(*np.log10([2, 200]), num=30) # this information should be stored in the metadata of your neural data recording. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the behavioral variables we plan to include as independent variables in our linear regression (`multi_reg_vars`) and the regressor of interest (`target_var`) we will permute to determine whether significant clusters encoding this behavioral variable exist in our time x frequency data. All continuous predictors should be normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set main predictor of interest for permutations *target_var must be a continuous numeric variable*\n",
    "target_var = 'error'\n",
    "\n",
    "# define subset of predictor variables from sample_behav to include in regression (should include target_var)\n",
    "multi_reg_vars = ['outcome','error']\n",
    "\n",
    "# subset input dataframe to include only multi_reg_vars\n",
    "predictor_data = sample_behav.copy()[multi_reg_vars]\n",
    "\n",
    "# let's print the first few rows of the predictor data to make sure it looks right\n",
    "predictor_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Perform within-electrode cluster test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a variable called `tfr_data` which is a `np.array` (dimensions should correspond with number of trials x number of frequencies x number of timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset demo channel data from sample_ieeg_dict and store as tfr_data variable: np.array of (num epochs x num frequencies x num times)\n",
    "demo_channel = 'channel_4'\n",
    "tfr_data     = sample_ieeg_dict[demo_channel]\n",
    "\n",
    "# check tfr_data dimensions - must be num trials, num frequencies, num timepoints\n",
    "tfr_data.shape \n",
    "print(f'Number of trials for {demo_channel}: {tfr_data.shape[0]}')\n",
    "print(f'Number of frequencies for {demo_channel}: {tfr_data.shape[1]}')\n",
    "print(f'Number of timepoints for {demo_channel}: {tfr_data.shape[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create an instance of `TFR_Cluster_Test`. This will be used to run the cluster test. It requires the tfr_data, predictor_data, target_var, and demo_channel as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(NeuroCluster.TFR_Cluster_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_test  = NeuroCluster.TFR_Cluster_Test(tfr_data,predictor_data,target_var,demo_channel)\n",
    "cluster_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate t-critical for a two-sided hypothesis test, we compute a T-distribution with N-K-1 degrees of freedom (N=number of samples, K = number of predictors in regression model) and find the t-values where the area of the t-distribution = 0.025 and 0.975 (1-alpha/ntails,alpha=0.05,ntails=2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plotting_utils.plot_tcritical(cluster_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are reading to run our linear regression based on the dependent neural variable (`tfr_data`) and independent behavioral variables (`predictor_data`, `target_var`) we passed as inputs to our `TFR_Cluster_Test` object. This will return pixel-level **β coefficients** and corresponding **t-statistics** for our TFR data in one electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas, tstats = cluster_test.tfr_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the **β coefficients** to give us an idea of the neural encoding pattern for our continuous predictor of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_beta_coef(betas,cluster_test,freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the **t-statistics** that correspond with the **β coefficient** for each time-frequency point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_tstats(tstats,cluster_test,freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's highlight **clusters** (defined as consecutive time x frequency points) with significant t-statistics. We can do this separately for both positive and negative clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_clusters(tstats,cluster_test,freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate True Cluster Statistic(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will identify the largest cluster (either/both positive and negative) and save the **cluster statistic** which will be our test statistic against our non-parametric null distribution. `max_tfr_cluster()` returns a dictionary containing the **cluster statistic**:`cluster_stat` and its associated **freq_idx**: `freq_idx` and **time_idx**:`time_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find largest cluster(s) and return the max cluster statistic(s) and cluster's  frequencies x times indices\n",
    "max_cluster_data  = cluster_test.max_tfr_cluster(tstats,max_cluster_output='all')\n",
    "print(f'Max positive cluster dictionary: {max_cluster_data[0]}')\n",
    "print(f'Max negative cluster dictionary: {max_cluster_data[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our largest cluster and its associated **cluster statistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_max_clusters(cluster_test,tstats,freqs)\n",
    "# TFR-Level Test Statistic: Largest Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Compute cluster p-value(s) from null distribution of cluster statistics. \n",
    "To generate the null distribution, perform non-parametric cluster-based permutation testing by randomly permuting predictor of interest (target_var). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have computed the true cluster statistics from our neural (`tfr_data`) and behavioral data (`predictor_data`, `target_var`). Next, we will permute our input data and re-run the cluster identification procedure on each permuted dataset. This will allow us to generate a null distribution of cluster statistics, which we can use to evaluate the statistical significance of the cluster statistics observed in our true data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_null_cluster_stats()` takes `num_permutations` as an input, which specifies the desired number of permutations. The function will permute the regressor of interest according to this number. It returns a list of null cluster statistics, with the length of the list depending on the tails of the test. Here we generated 100 null cluster statistics, `num_permutations=100`, but we recommend running at least 200 permutations (500 to 1000 is best practice). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cluster_distribution = cluster_test.compute_null_cluster_stats(num_permutations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cluster_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the ***p*-value** associated with our true cluster statistics based on the null distributions we create using `cluster_significance_test()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pvalue = cluster_test.cluster_significance_test(max_cluster_data,null_cluster_distribution) \n",
    "print(f'Positive cluster p-value: {cluster_pvalue[0]}')\n",
    "print(f'Negative cluster p-value: {cluster_pvalue[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a plot showing the **null distribution(s)** we generated, with our true cluster statistic overlaid on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_null_distribution(null_cluster_distribution, max_cluster_data,cluster_pvalue,dpi=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all plots\n",
    "tstat_threshold = cluster_test.threshold_tfr_tstat(tstats)\n",
    "tcrit_plot,beta_plot,tstat_plot,cluster_plot,max_cluster_plot,null_distribution_plot = NeuroCluster.plot_neurocluster_results(betas,cluster_test,\n",
    "                                                                                                                    max_cluster_data, null_cluster_distribution, tstats, tstat_threshold,cluster_pvalue,freqs)\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "output_directory = f'{results_dir}/{demo_channel}_{target_var}'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "NeuroCluster.create_directory(output_directory)\n",
    "\n",
    "# Save plots to the output directory\n",
    "NeuroCluster.save_plot_to_pdf(tcrit_plot, output_directory, f'{cluster_test.alternative}_tcrit_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(beta_plot, output_directory, f'{cluster_test.alternative}_beta_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(tstat_plot, output_directory, f'{cluster_test.alternative}_tstat_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(cluster_plot, output_directory, f'{cluster_test.alternative}_cluster_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(max_cluster_plot, output_directory, f'{cluster_test.alternative}_max_cluster_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(null_distribution_plot, output_directory, f'{cluster_test.alternative}_null_distribution_plot.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Sided Hypothesis Test Example\n",
    "Rather than testing whether a tfr cluster significantly encodes our `target_var` in general, we can evaluate the directionality of `target_var` encoding in our cluster. Specifically, we can test whether neuronal activity in a cluster increases (or decreases) with increasing (or decreasing) values of the `target_var`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_test  = NeuroCluster.TFR_Cluster_Test(tfr_data,predictor_data,target_var,demo_channel,alternative='greater')\n",
    "cluster_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate t-critical for a one-sided hypothesis test, we compute a T-distribution with N-K-1 degrees of freedom (N=number of samples, K = number of predictors in regression model) and find the t-value where the area of the t-distribution = 0.95 (1-alpha,alpha=0.05). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plotting_utils.plot_tcritical(cluster_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are reading to run our linear regression based on the dependent neural variable (`tfr_data`) and independent behavioral variables (`predictor_data`, `target_var`) we passed as inputs to our `TFR_Cluster_Test` object. This will return pixel-level **β coefficients** and corresponding **t-statistics** for our TFR data in one electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas, tstats = cluster_test.tfr_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the **β coefficients** to give us an idea of the neural encoding pattern for our continuous predictor of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_beta_coef(betas,cluster_test,freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the **t-statistics** that correspond with the **β coefficient** for each time-frequency point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_tstats(tstats,cluster_test,freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's highlight **clusters** (defined as consecutive time x frequency points) with significant t-statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_clusters(tstats,cluster_test,freqs,figsize=(6,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate True Cluster Statistic(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will identify the largest cluster (either/both positive and negative) and save the **cluster statistic** which will be our test statistic against our non-parametric null distribution. `max_tfr_cluster()` returns a dictionary containing the **cluster statistic**:`cluster_stat` and its associated **freq_idx**: `freq_idx` and **time_idx**:`time_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find largest cluster(s) and return the max cluster statistic(s) and cluster's  frequencies x times indices\n",
    "max_cluster_data  = cluster_test.max_tfr_cluster(tstats,max_cluster_output='all')\n",
    "print(f'Max positive cluster dictionary: {max_cluster_data[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our **positive** largest cluster and its associated **cluster statistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_max_clusters(cluster_test,tstats,freqs,figsize=(6,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Compute cluster p-value(s) from null distribution of cluster statistics. \n",
    "To generate the null distribution, perform non-parametric cluster-based permutation testing by randomly permuting predictor of interest (target_var). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have computed the true cluster statistics from our neural (`tfr_data`) and behavioral data (`predictor_data`, `target_var`). Next, we will permute our input data and re-run the cluster identification procedure on each permuted dataset. This will allow us to generate a null distribution of cluster statistics, which we can use to evaluate the statistical significance of the cluster statistics observed in our true data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_null_cluster_stats()` takes `num_permutations` as an input, which specifies the desired number of permutations. The function will permute the regressor of interest according to this number. It returns a list of null cluster statistics, with the length of the list depending on the tails of the test. Here we generated 100 null cluster statistics, `num_permutations=100`, but we recommend running at least 200 permutations (500 to 1000 is best practice). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cluster_distribution = cluster_test.compute_null_cluster_stats(num_permutations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the ***p*-value** associated with our true cluster statistics based on the null distributions we create using `cluster_significance_test()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pvalue = cluster_test.cluster_significance_test(max_cluster_data,null_cluster_distribution) \n",
    "print(f'Positive cluster p-value: {cluster_pvalue[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a plot showing the **null distribution(s)** we generated, with our true cluster statistic overlaid on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuroCluster.plot_null_distribution(null_cluster_distribution, max_cluster_data,cluster_pvalue,figsize=(6,5),dpi=125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to replicate findings using MNE's built-in t-test functionality\n",
    "\n",
    "When using a t-test to analyze a continuous variable, there is a risk of encountering false negatives (i.e., failing to detect a true effect), as demonstrated in this example. This issue arises because the t-test may not fully capture the complexity or structure of the data, leading to inaccurate conclusions. This underscores the advantages of NeuroCluster's approach, which provides a more robust method for capturing complex data structures and reducing the risk of false negatives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if we get the same result as Neurocluster (a significant positive cluster meaning as error increases, encoding increases), using mne's built-in two sample t-test cluster function\n",
    "import mne\n",
    "\n",
    "# Let's take a median split for the error variable and assign it to high and low error variables (we need to discretize the error variable for the mne function)\n",
    "error = sample_behav['error']\n",
    "median_error = np.median(error)\n",
    "low_error = tfr_data[error < median_error, :, :]    \n",
    "high_error = tfr_data[error >= median_error, :, :]\n",
    "\n",
    "# Let's run the mne two sample t-test cluster function\n",
    "t_obs, clusters, cluster_pv, H0 = mne.stats.permutation_cluster_test([low_error, high_error], n_permutations=1000, tail=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_c, c in enumerate(clusters):\n",
    "    c = c[0]\n",
    "    if cluster_pv[i_c] <= 0.05:\n",
    "        print(f\"Cluster {i_c} p-value: {cluster_pv[i_c]}\")\n",
    "    else:\n",
    "        print(\"No significant clusters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run the entire pipeline at once and save plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NeuroCluster single electrode workflow: \n",
    "\n",
    "# Step 1: Create TFR_Cluster_Test Object\n",
    "cluster_test  = NeuroCluster.TFR_Cluster_Test(tfr_data,predictor_data,target_var,demo_channel,alternative='two-sided')\n",
    "\n",
    "# Step 2: Run TFR regression to extract beta coefficients for predictor of interest (permute_var) & tstats for each pixel in TFR. Determine which t-statistics are significant based on the critical t-value and save a thresholded t-statistic matrix.\n",
    "betas, tstats = cluster_test.tfr_regression()\n",
    "tstat_threshold = cluster_test.threshold_tfr_tstat(tstats)\n",
    "\n",
    "# Step 3: Find largest cluster(s) and return the max cluster statistic(s) and cluster's  frequencies x times indices\n",
    "max_cluster_data  = cluster_test.max_tfr_cluster(tstats,max_cluster_output='all')\n",
    "\n",
    "# Step 4: Create null distribution of maximum cluster statistics from permuted data\n",
    "null_cluster_distribution = cluster_test.compute_null_cluster_stats(num_permutations=100)\n",
    "\n",
    "# Step 5: Use null cluster statistic distribution from permutations to compute non-parametric p value \n",
    "cluster_pvalue = cluster_test.cluster_significance_test(max_cluster_data,null_cluster_distribution) \n",
    "\n",
    "# Let's plot all the steps together and save the figures to a dictory that corresponds to the channel and predictor of interest. \n",
    "tcrit_plot,beta_plot,tstat_plot,cluster_plot,max_cluster_plot,null_distribution_plot = NeuroCluster.plot_neurocluster_results(betas,cluster_test, max_cluster_data, null_cluster_distribution, tstats, tstat_threshold,cluster_pvalue,freqs)\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "output_directory = f'{results_dir}/{demo_channel}_{target_var}'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "NeuroCluster.create_directory(output_directory)\n",
    "\n",
    "# Save plots to the output directory\n",
    "NeuroCluster.save_plot_to_pdf(beta_plot, output_directory, 'beta_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(tstat_plot, output_directory, 'tstat_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(cluster_plot, output_directory, 'cluster_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(max_cluster_plot, output_directory, 'max_cluster_plot.pdf')\n",
    "NeuroCluster.save_plot_to_pdf(null_distribution_plot, output_directory, 'null_distribution_plot.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurocluster_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
