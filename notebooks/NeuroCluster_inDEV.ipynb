{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroCluster:\n",
    "<font size= 4> Non-parametric cluster-based permutation testing to identify neurophysiological encoding of continuous variables with time-frequency resolution\n",
    "\n",
    "Authors: Christina Maher & Alexandra Fink-Skular \\\n",
    "Updated: 06/19/2024 by CMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from glob import glob\n",
    "from scipy.stats import zscore, t, linregress, ttest_ind, ttest_rel, ttest_1samp \n",
    "import os \n",
    "import re\n",
    "import h5io\n",
    "import pickle \n",
    "import time \n",
    "import datetime \n",
    "from joblib import Parallel, delayed\n",
    "import statsmodels.api as sm \n",
    "from scipy.ndimage import label \n",
    "import statsmodels.formula.api as smf\n",
    "import tqdm\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# keep this so we can use our respective paths for testing\n",
    "current_user = 'christina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_user == 'christina':\n",
    "    base_dir = '/Users/christinamaher/Documents/GitHub/NeuroCluster/scripts/'\n",
    "    data_dir = '/Users/christinamaher/Documents/GitHub/NeuroCluster/'\n",
    "    tfr_dir  = f'{data_dir}tfr/'\n",
    "    anat_dir = f'{data_dir}anat/'\n",
    "elif current_user == 'alie':\n",
    "    base_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/NeuroCluster/'\n",
    "    data_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/'\n",
    "    tfr_dir  = f'{data_dir}ephys_analysis/data/'\n",
    "    beh_dir  = f'{data_dir}behavior_analysis/behavior_preprocessed/'\n",
    "    anat_dir = f'{data_dir}anat_recons/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions \n",
    "import sys\n",
    "sys.path.append(base_dir)\n",
    "from tfr_cluster_test import *\n",
    "from helper_utils import *\n",
    "#from plotting_utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today().strftime('%m%d%Y')\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Format Input Data (Currently within-subject)\n",
    "- neural input: np.array (n_channels x n_epochs x n_freqs x n_times)\n",
    "- regressor data: np.array (numpy array: n_epochs x n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load epoched data for single subj\n",
    "if current_user == 'alie':\n",
    "    subj_id     = 'MS002'   \n",
    "    power_epochs = mne.time_frequency.read_tfrs(fname=f'{tfr_dir}{subj_id}/{subj_id}_CpeOnset-tfr.h5')[0]\n",
    "elif current_user == 'christina':\n",
    "    subj_id     = 'MS009'   \n",
    "    power_epochs = mne.time_frequency.read_tfrs(fname=f'{tfr_dir}/{subj_id}_tfr.h5')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ROI for single ROI anaylsis \n",
    "if current_user == 'alie':\n",
    "    roi = 'ains'\n",
    "    # set all variables included mutliple regression \n",
    "    multi_reg_vars = ['GambleChoice','TotalProfit','RPE','decisionCPE']\n",
    "    # set main variable of interest for permutations \n",
    "    permute_var = 'decisionCPE'\n",
    "\n",
    "    roi_subj_beh_df = []\n",
    "\n",
    "    for subj_id in roi_subj_ids: \n",
    "        # load subj behavior data \n",
    "        beh_df = pd.read_csv(f'{beh_dir}{subj_id}_task_data')\n",
    "        # clean subj dataframe from fail trials/nan values in vars of interest \n",
    "        # beh_df[~(beh_df.GambleChoice=='gamble')|~(beh_df.GambleChoice=='safe')] = np.nan\n",
    "        # beh_df = beh_df[~beh_df.Outcome.isnull()]\n",
    "        beh_df['GambleChoice'][(beh_df.GambleChoice!='gamble')&(beh_df.GambleChoice!='safe')&(~beh_df.GambleChoice.isnull())] = np.nan\n",
    "        # beh_df = beh_df[(beh_df.GambleChoice=='gamble')|(beh_df.GambleChoice=='safe')]\n",
    "        # beh_df = beh_df[~beh_df.Outcome.isnull()]\n",
    "        # set datatypes for categorical vars\n",
    "        beh_df['GambleChoice'] = beh_df['GambleChoice'].astype('category')\n",
    "        beh_df['subj_id'] = subj_id\n",
    "        beh_df[multi_reg_vars[1:]] = pd.DataFrame({f'{var}':zscore(beh_df[var])  for var in multi_reg_vars[1:]})\n",
    "        # beh_df = beh_df[['subj_id','Round'] + multi_reg_vars]\n",
    "        beh_df = beh_df[['subj_id','Round'] + multi_reg_vars]    \n",
    "        roi_subj_beh_df.append(beh_df)\n",
    "\n",
    "    roi_subj_beh_df = pd.concat(roi_subj_beh_df).reset_index(drop=True)\n",
    "    roi_subj_beh_df['GambleChoice'] = roi_subj_beh_df['GambleChoice'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_df = prepare_regressor_df(power_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new function for getting elecs in ROI\n",
    "roi = ['lpfc','ofc']\n",
    "roi_subj_elecs = prepare_anat_dic(roi, f'{anat_dir}master_labels.csv')\n",
    "roi_subj_elecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Univariate Regression \n",
    "- Use TFRClusterTest class code to run univariate regression\n",
    "- Allows for multiple regression implementation and pixel paralellization, so with more speed improvements will ultimately be worth it. (ONGOING DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### class TFR_Cluster_Test dev + debugging\n",
    "\n",
    "if current_user == 'alie':\n",
    "\n",
    "    # subset single electrode tfr data + behav data\n",
    "    tfr_data = np.squeeze(power_epochs._data[:,16,:,:].copy())\n",
    "    predictor_data = roi_subj_beh_df[roi_subj_beh_df.subj_id == 'MS002'].drop(columns=['subj_id','Round'])\n",
    "\n",
    "    test_univar = predictor_data[permute_var].copy()\n",
    "\n",
    "elif current_user == 'christina':\n",
    "    \n",
    "        # subset single electrode tfr data + behav data\n",
    "        tfr_data = np.squeeze(power_epochs._data[:,0,:,:].copy())\n",
    "        ch_name = power_epochs.info['ch_names'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_var = 'ev_zscore'\n",
    "ch_name = power_epochs.info['ch_names'][0]\n",
    "cluster_test = TFR_Cluster_Test(tfr_data,beh_df,permute_var,ch_name)\n",
    "betas, tstats = cluster_test.tfr_multireg()\n",
    "cluster_data = cluster_test.max_tfr_cluster(tstats)\n",
    "\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta_coef(betas, cluster_test):\n",
    "\n",
    "    plt.imshow(betas, interpolation = 'Bicubic',cmap='Spectral_r', aspect='auto',origin='lower',vmin=-.5,vmax=.5) \n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Freq')\n",
    "    plt.xlabel('Time')\n",
    "    # make title dynamic depending on whether or not you are controlling for other variables\n",
    "    if cluster_test.predictor_data.columns.tolist() == [cluster_test.permute_var]:\n",
    "        plt.title(f'Beta coefficients from {cluster_test.ch_name} encoding {cluster_test.permute_var}')\n",
    "    else:\n",
    "        beh_variables = cluster_test.predictor_data.columns.tolist().copy()\n",
    "        control_variables = beh_variables.remove(cluster_test.permute_var) # to do - fix this bc its not printing as it should \n",
    "        plt.title(f'Beta coefficients from {cluster_test.ch_name} encoding {cluster_test.permute_var} controlling for {control_variables}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_tstats(tstats, cluster_test):\n",
    "\n",
    "    plt.imshow(tstats, interpolation = 'Bicubic',cmap='Spectral_r', aspect='auto',origin='lower',vmin=-3,vmax=3) \n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Freq')\n",
    "    plt.xlabel('Time')\n",
    "    # make title dynamic depending on whether or not you are controlling for other variables\n",
    "    if cluster_test.predictor_data.columns.tolist() == [cluster_test.permute_var]:\n",
    "        plt.title(f'T-statistics for beta coefficients from {cluster_test.ch_name} encoding {cluster_test.permute_var}')\n",
    "    else:\n",
    "        beh_variables = cluster_test.predictor_data.columns.tolist().copy()\n",
    "        control_variables = beh_variables.remove(cluster_test.permute_var) # to do - fix this because its not printing as it should \n",
    "        plt.title(f'T-statistics for beta coefficents from {cluster_test.ch_name} encoding {cluster_test.permute_var} controlling for {control_variables}')\n",
    "    plt.show()\n",
    "\n",
    "def plot_clusterstats(cluster_data, tstats, cluster_test):\n",
    "\n",
    "    # Loop through the list of dictionaries\n",
    "    for cluster in cluster_data:\n",
    "        # Initialize an array the same shape as the tstat\n",
    "        masked_tstat_plot = np.zeros_like(tstats)\n",
    "\n",
    "        # Extract the indices from the dictionary\n",
    "        freq_start, freq_end = cluster['freq_idx']\n",
    "        time_start, time_end = cluster['time_idx']\n",
    "\n",
    "        # Copy the values from tstat_plot to masked_tstat_plot for the significant cluster range\n",
    "        masked_tstat_plot[freq_start:freq_end+1, time_start:time_end+1] = 1\n",
    "\n",
    "        # Plot the masked tstat plot\n",
    "        plt.imshow(masked_tstat_plot, interpolation='bicubic', cmap='Spectral_r', aspect='auto', origin='lower', vmin=-3, vmax=3)\n",
    "        plt.ylabel('Freq')\n",
    "        plt.xlabel('Time')\n",
    "        plt.title(f'Significant cluster from {cluster_test.ch_name} encoding {cluster_test.permute_var}')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_beta_coef(betas, cluster_test)\n",
    "plot_tstats(tstats, cluster_test)\n",
    "plot_clusterstats(cluster_data, tstats, cluster_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Multiple Regression \n",
    "- Using TFRClusterTest class\n",
    "- Need to implement the permutation version of this code (ONGOING DEV)\n",
    "- Need to add more functionality + plotting utils (ONGOING DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop certain columns from predictor data\n",
    "predictor_data = predictor_data.drop(columns=['condition','chosen_shape_current_trial','chosen_color_current_trial','chosen_shape_previous_trial','chosen_color_previous_trial','ev'])\n",
    "predictor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_test = TFR_Cluster_Test(tfr_data,predictor_data,permute_var)\n",
    "elec_betas, elec_tstats = elec_test.tfr_multireg()\n",
    "elec_cluster_data = elec_test.max_tfr_cluster(elec_tstats)\n",
    "\n",
    "elec_cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(elec_betas, interpolation = 'Bicubic',cmap='Spectral_r', aspect='auto',origin='lower',vmin=-.5,vmax=.5) \n",
    "plt.colorbar()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Freq')\n",
    "plt.title(f'{power_epochs.ch_names[16]} - beta coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Extract Surrogate Clusters from Pixel-wise Permutation\n",
    "- For loop for each electrode- \n",
    "- Run each permutation (1000x) in parallel within electrode loop\n",
    "- Calculate max cluster p value for each +/- cluster for each electrode\n",
    "- Save permuted cluster statistics for each electrode \n",
    "\n",
    "DEPENDENCIES: permuted_tfr_cluster_test, tfr_cluster_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS THE NEW PERMUTATION IMPLEMENTATION \n",
    "cluster_test = TFR_Cluster_Test(tfr_data,predictor_data,permute_var)\n",
    "perm_cluster_results = run_permutation_test(cluster_test, num_permutations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list to store cluster data\n",
    "cluster_list = []\n",
    "\n",
    "for p in range(1000):\n",
    "    uni_test = TFR_Cluster_Test(tfr_data,pd.DataFrame(test_univar),permute_var,1000)\n",
    "    _, uni_tstats = uni_test.tfr_multireg()\n",
    "    cluster_data = uni_test.max_tfr_cluster(uni_tstats,output='cluster_stat') \n",
    "    # add permutation number to cluster data\n",
    "    cluster_data['perm_num'] = p\n",
    "    del uni_test, uni_tstats # clear memory\n",
    "    cluster_list.append(cluster_data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST PERMUTATIONS \n",
    "num_permutations = 1000\n",
    "start = time.time() # start timer\n",
    "\n",
    "all_ch_perm = {}\n",
    "\n",
    "for c in range(num_channels):\n",
    "        ch_start = time.time() # start timer\n",
    "\n",
    "        # Prepare arguments for the permutation function\n",
    "        permutation_args = [\n",
    "        (np.squeeze(power_epochs._data[:,c,:,:]), reg_data, tcritical)\n",
    "        for _ in range(num_permutations)]\n",
    "    \n",
    "        # Perform permutations in parallel\n",
    "        elec_permuted_data = Parallel(n_jobs=-1, verbose=12)(\n",
    "        delayed(permuted_tfr_cluster_test)(*args)\n",
    "        for args in permutation_args)\n",
    "        \n",
    "        # save in all elec dict \n",
    "        all_ch_perm[ch_names[c]] = elec_permuted_data\n",
    "        pickle.dump(elec_permuted_data, open(f'{results_dir}{subj_id}_{ch_names[c]}_perm_clusters.pkl', \"wb\")) \n",
    "\n",
    "        ch_end = time.time() \n",
    "        print(f'{ch_names[c]} permute time: ', '{:.2f}'.format(ch_end-ch_start))\n",
    "        \n",
    "        \n",
    "\n",
    "end = time.time()    \n",
    "print('{:.2f} s'.format(end-start)) # print time elapsed for computation (approx 4 seconds per permutation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations = 1000\n",
    "ch_start = time.time() # start timer\n",
    "\n",
    "# Prepare arguments for the permutation function\n",
    "permutation_args = [\n",
    "(np.squeeze(power_epochs._data[:,c,:,:]), reg_data, tcritical)\n",
    "for _ in range(num_permutations)]\n",
    "\n",
    "# Perform permutations in parallel\n",
    "elec_permuted_data_reduc = Parallel(n_jobs=-1, verbose=12)(\n",
    "delayed(permuted_tfr_cluster_test)(*args)\n",
    "for args in permutation_args)\n",
    "\n",
    "# save in all elec dict \n",
    "# all_ch_perm[ch_names[c]] = elec_permuted_data\n",
    "pickle.dump(elec_permuted_data_reduc, open(f'{results_dir}{subj_id}_{ch_names[c]}_reduced_output_perm_clusters.pkl', \"wb\")) \n",
    "\n",
    "ch_end = time.time() \n",
    "print(f'{ch_names[c]} permute time: ', '{:.2f}'.format(ch_end-ch_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_permuted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_permuted_data_reduc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swb_ephys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
