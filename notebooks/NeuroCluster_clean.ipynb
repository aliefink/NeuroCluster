{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroCluster:\n",
    "<font size= 4> Non-parametric cluster-based permutation testing to identify neurophysiological encoding of continuous variables with time-frequency resolution\n",
    "\n",
    "Authors: Christina Maher & Alexandra Fink-Skular \\\n",
    "Updated: 07/23/2024 by AFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from glob import glob\n",
    "from scipy.stats import zscore\n",
    "# import time \n",
    "import datetime \n",
    "from joblib import Parallel, delayed\n",
    "import statsmodels.api as sm \n",
    "from scipy.ndimage import label \n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# keep this so we can use our respective paths for testing\n",
    "# current_user = 'christina'\n",
    "current_user = 'alie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07242024\n"
     ]
    }
   ],
   "source": [
    "date = datetime.date.today().strftime('%m%d%Y')\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_user == 'christina':\n",
    "    base_dir = '/Users/christinamaher/Documents/GitHub/NeuroCluster/scripts/'\n",
    "    data_dir = '/Users/christinamaher/Documents/GitHub/NeuroCluster/'\n",
    "    tfr_dir  = f'{data_dir}tfr/'\n",
    "    anat_dir = f'{data_dir}anat/'\n",
    "elif current_user == 'alie':\n",
    "    base_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/NeuroCluster/NeuroCluster/NeuroCluster/scripts/'\n",
    "    data_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/'\n",
    "    tfr_dir  = f'{data_dir}ephys_analysis/data/'\n",
    "    beh_dir  = f'{data_dir}behavior_analysis/behavior_preprocessed/'\n",
    "    anat_dir = f'{data_dir}anat_recons/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions \n",
    "import sys\n",
    "sys.path.append(f'{base_dir}')\n",
    "# sys.path.append(f'{base_dir}scripts/')\n",
    "\n",
    "from tfr_cluster_test import *\n",
    "from helper_utils import *\n",
    "from plotting_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Format Input Data (Currently within-subject)\n",
    "- neural input: np.array (n_channels x n_epochs x n_freqs x n_times)\n",
    "- regressor data: np.array (numpy array: n_epochs x n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/ephys_analysis/data/MS002/MS002_CpeOnset-tfr.h5 ...\n",
      "Adding metadata with 19 columns\n"
     ]
    }
   ],
   "source": [
    "# load epoched data for single subj\n",
    "if current_user == 'alie':\n",
    "    permute_var = 'decisionCPE'\n",
    "    subj_id     = 'MS002'   \n",
    "    power_epochs = mne.time_frequency.read_tfrs(fname=f'{tfr_dir}{subj_id}/{subj_id}_CpeOnset-tfr.h5')[0]\n",
    "elif current_user == 'christina':\n",
    "    permute_var = 'ev_zscore'\n",
    "    subj_id     = 'MS009'   \n",
    "    power_epochs = mne.time_frequency.read_tfrs(fname=f'{tfr_dir}{subj_id}_tfr.h5')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ROI for single ROI anaylsis \n",
    "if current_user == 'alie':\n",
    "#     roi = 'ains'\n",
    "    # set all variables included mutliple regression \n",
    "    multi_reg_vars = ['GambleChoice','TrialEV','decisionCPE']\n",
    "    # set main variable of interest for permutations \n",
    "    permute_var = 'decisionCPE'\n",
    "    # load subj behavior data \n",
    "#     beh_df = pd.read_csv(f'{beh_dir}{subj_id}_task_data')\n",
    "    beh_df = power_epochs.metadata.copy()\n",
    "    # beh_df['subj_id'] = subj_id\n",
    "    # add TrialEV to df\n",
    "    beh_df['TrialEV'] = beh_df.GambleEV - beh_df.SafeBet\n",
    "    # clean subj dataframe from fail trials/nan values in vars of interest     \n",
    "    # beh_df = beh_df[(beh_df.GambleChoice=='gamble')|(beh_df.GambleChoice=='safe')]\n",
    "#     beh_df = beh_df[(beh_df.Outcome=='good')|(beh_df.Outcome=='bad')]\n",
    "    \n",
    "    # zscore continuous variables \n",
    "    beh_df[multi_reg_vars[1:]] = pd.DataFrame({f'{var}':zscore(beh_df[var])  for var in multi_reg_vars[1:]})\n",
    "    # format final beh_df\n",
    "    beh_df = beh_df[multi_reg_vars].reset_index(drop=True) \n",
    "    # convert choice to categorical variable\n",
    "    beh_df['GambleChoice'] = beh_df['GambleChoice'].astype('category')\n",
    "\n",
    "elif current_user == 'christina':\n",
    "    behavior = pd.read_csv('/Users/christinamaher/Desktop/old_preprocess/MS009/MS009_clean.csv')\n",
    "    power_epochs.metadata['ev_zscore'] = behavior['expected_value'].values\n",
    "    power_epochs = power_epochs[\"condition == 'hint'\"]\n",
    "    beh_df = prepare_regressor_df(power_epochs)\n",
    "    # assign column names for to multi_reg_vars list\n",
    "    multi_reg_vars = beh_df.columns.tolist()\n",
    "    ## new function for getting elecs in ROI\n",
    "    roi = ['lpfc','ofc']\n",
    "    roi_subj_elecs = prepare_anat_dic(roi, f'{anat_dir}master_labels.csv')\n",
    "    roi_subj_elecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### class TFR_Cluster_Test dev + debugging\n",
    "\n",
    "if current_user == 'alie':\n",
    "\n",
    "    # subset single electrode tfr data + behav data\n",
    "    dev_ch_idx     = power_epochs.ch_names.index('laims2-laims3')\n",
    "    ch_name        = 'laims2-laims3'\n",
    "    tfr_data       = np.squeeze(power_epochs._data[:,dev_ch_idx,:,:].copy())\n",
    "    predictor_data = beh_df.copy()\n",
    "    \n",
    "    # predictor_data = predictor_data.drop(columns='subj_id')\n",
    "\n",
    "elif current_user == 'christina':\n",
    "    \n",
    "        # subset single electrode tfr data + behav data\n",
    "        # predictor_data = predictor_data.drop(columns=['condition','chosen_shape_current_trial','chosen_color_current_trial','chosen_shape_previous_trial','chosen_color_previous_trial','ev'])\n",
    "        tfr_data = np.squeeze(power_epochs._data[:,0,:,:].copy())\n",
    "        ch_name = power_epochs.info['ch_names'][0]\n",
    "        predictor_data = beh_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POLISHED WORKFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3336 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 42968 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 45030 out of 45030 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "### NeuroCluster single electrode workflow: \n",
    "\n",
    "# Step 1: Create TFR_Cluster_Test Object\n",
    "cluster_test  = TFR_Cluster_Test(tfr_data,predictor_data,permute_var,ch_name,alternative='two-sided')\n",
    "\n",
    "# Step 2: Run TFR regression to extract beta coefficients for predictor of interest (permute_var) & tstats for each pixel in TFR\n",
    "betas, tstats = cluster_test.tfr_regression()\n",
    "\n",
    "# Optional step but necessary for plotting - save matrices with location of t-stats that survive significance thresholding\n",
    "tstat_threshold = cluster_test.threshold_tfr_tstat(tstats)\n",
    "\n",
    "# Step 3: Find largest cluster(s) and return the max cluster statistic(s) and cluster's  frequencies x times indices\n",
    "max_cluster_data  = cluster_test.max_tfr_cluster(tstats,output='all')\n",
    "\n",
    "# Step 4: Create null distribution of maximum cluster statistics from permuted data\n",
    "null_cluster_distribution = cluster_test.compute_null_cluster_stats(num_permutations=10)\n",
    "\n",
    "# Step 5: Use null cluster statistic distribution from permutations to compute non-parametric p value \n",
    "cluster_pvalue = cluster_test.cluster_significance_test(max_cluster_data,null_cluster_distribution) #compute_cluster_pvalue cluster_significance_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POLISHED PLOTTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_plot,tstat_plot,cluster_plot,max_cluster_plot,null_distribution_plot = plot_neurocluster_results(betas,cluster_test, max_cluster_data, null_cluster_distribution, tstats, tstat_threshold)\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "output_directory = f'{data_dir}/{ch_name}_{permute_var}'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "create_directory(output_directory)\n",
    "\n",
    "# Save each plot to the directory with a specific filename\n",
    "save_plot_to_pdf(beta_plot, output_directory, 'beta_plot.png')\n",
    "save_plot_to_pdf(tstat_plot, output_directory, 'tstat_plot.png')\n",
    "save_plot_to_pdf(cluster_plot, output_directory, 'cluster_plot.png')\n",
    "save_plot_to_pdf(max_cluster_plot, output_directory, 'max_cluster_plot.png')\n",
    "save_plot_to_pdf(null_distribution_plot, output_directory, 'null_distribution_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To implement FDR correction: \n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html\n",
    "# multitest.multipletests(p_upper, method='fdr_bh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swb_ephys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
